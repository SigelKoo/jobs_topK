- [OSI七层模型](#osi七层模型)
- [Redis数据结构](#redis数据结构)
- [TCP的可靠性](#tcp的可靠性)
- [RST](#rst)
- [socket重启 端口被占用](#socket重启-端口被占用)
- [乐观锁和悲观锁](#乐观锁和悲观锁)
- [CPU占用率过高](#cpu占用率过高)
- [DNS](#dns)
- [golang常用数据结构占用内存大小](#golang常用数据结构占用内存大小)
- [进程间通信](#进程间通信)
- [死锁](#死锁)
- [数组与链表](#数组与链表)
- [二叉树与二叉搜索树](#二叉树与二叉搜索树)
- [网络通信，客户端意外断开](#网络通信客户端意外断开)
- [explain](#explain)
- [URL解析详情](#url解析详情)
- [三次握手](#三次握手)
- [四次挥手](#四次挥手)
- [访问IP没有加端口](#访问ip没有加端口)
- [哪些列创建索引](#哪些列创建索引)
- [聚簇索引](#聚簇索引)
- [ACID各属性的体现](#acid各属性的体现)
- [Redis持久化](#redis持久化)
- [Redis模型](#redis模型)
- [go sync.map](#go-syncmap)
- [HTTPS加密过程](#https加密过程)
- [fork](#fork)
- [进程的虚拟地址空间划分](#进程的虚拟地址空间划分)
- [字典树](#字典树)
- [自动补全实现](#自动补全实现)
- [单词纠错](#单词纠错)
- [TCP与UDP](#tcp与udp)
- [数据库隔离级别](#数据库隔离级别)
- [TCP粘包](#tcp粘包)
- [查找打开特定端口的进程](#查找打开特定端口的进程)
- [存IP地址使用什么数据类型比较好](#存ip地址使用什么数据类型比较好)
- [CAP](#cap)
- [MVCC](#mvcc)
- [ping用到了哪些协议](#ping用到了哪些协议)
- [IO多路复用](#io多路复用)
- [pdqsort](#pdqsort)
- [长肥管道](#长肥管道)
- [mysql的limit分页，越往后为什么越慢，怎么解决](#mysql的limit分页越往后为什么越慢怎么解决)
- [主键使用自增和随机字符串](#主键使用自增和随机字符串)
# OSI七层模型

![img](https://camo.githubusercontent.com/4878cb79896772f456bf3be289c7b34dd46573d0a14bc7c22df1c6eeea2e7219/68747470733a2f2f696d672d626c6f672e6373646e2e6e65742f32303138303431313132303730323433383f77617465726d61726b2f322f746578742f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c334678587a4d354e5449784e5455302f666f6e742f3561364c354c32542f666f6e7473697a652f3430302f66696c6c2f49304a42516b46434d413d3d2f646973736f6c76652f3730)

![img](https://camo.githubusercontent.com/f5e51c1d24fb1a86536470eba7c13e03112eecf2723a784ef8986b7e4a62bd79/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d33343330393336343536333865613038333962373164623565626131663763305f373230772e6a7067)

![img](https://camo.githubusercontent.com/00ef919ebc6ae4f70e607fb2fe791af650336388b92dbaf7ac8f189b2440a70a/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d66623835333464383665343039383665343334343964653663333565626431345f373230772e6a7067)

![img](https://camo.githubusercontent.com/eb0458d1cd2641c62a03fbd2df5067a816234c194f4669a4c4dd394bc449a411/68747470733a2f2f706963342e7a68696d672e636f6d2f38302f76322d39393135373238323539393035373564323733663635336137386263633565375f373230772e6a7067)

![img](https://camo.githubusercontent.com/2ffb01953c1e1bcd74632bdca859ada4030d47cfa76be9b0dcbc27dac20e6fd7/68747470733a2f2f706963322e7a68696d672e636f6d2f38302f76322d33316266663534653037323034383761666533376535663366323832643233315f373230772e6a7067)

![img](https://camo.githubusercontent.com/d169cbb8f0f53798c1fa970fbc0a4dd9d4d232036f742bff779489bda6487e41/68747470733a2f2f706963322e7a68696d672e636f6d2f38302f76322d37343165346364376639353839376436613631626432313965323038663163315f373230772e6a7067)

# Redis数据结构

- String 字符串：SDS类型，可以存储二进制数据，获取字符串长度复杂度为O(1)。
- List列表：QuickList类型，双向链表。
- Hash哈希：键值对映射表。
- Set：无序集合。
- Sorted Set：有序集合。ziplist或者skiplist。
- HyperLogLog：统计信息，有多少用户登录。
- GEO：地理位置信息（经度、纬度、位置名称）。
- 布隆过滤器。

# TCP的可靠性

- 校验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。TCP在计算检验和时，会在TCP首部加上一个12字节的伪首部。检验和总共计算3部分：TCP首部、TCP数据、TCP伪首部。
- 序列号/响应应答：发送端传输一个包，接收端没有回应确认包，就会重发；接收端的应答包，发送端没有收到也会重发。
- 超时重传：TCP的发送方在规定的时间内（重传时间 ）没有收到确认就要重传已发送的报文段。即超时重传。
- 最大消息长度：MSS。
- 滑动窗口控制：接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小，用变量win来表示接收窗口的大小。发送方的发送窗口取接收窗口rwnd和拥塞窗口cwnd的最小值。
- 拥塞控制：慢开始、拥塞避免、快重传、快恢复。

![image-20201229230755983](https://camo.githubusercontent.com/f20cef5faefa071aab9a54e7ec8869872fd291bad7f339cb7afd6f521d3a84d6/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f34323162386636346335643332376263323835613764616630373061643231662e706e67)

开始时cwnd=1，为一个报文段；开始慢开始算法阶段1->2->4->8->16，到达慢开始门限（ssthresh）；切换算法，由慢开始算法切换到拥塞避免算法“加法增大”，16->17->18->19->20->21->22->23->24；到达24，开始网络拥塞；从cwnd为1重新开始慢开始算法，执行“乘法减小”算法，把ssthresh门限减半（12），1->2->4->8->12，到达慢开始门限；切换算法，由慢开始算法切换到拥塞避免算法“加法增大”，12->13->14->15->16......

![image-20201229231047273](https://camo.githubusercontent.com/50842debcd82e409724fca45b0ecb5ba8f27437b4fa769cfb12d5520d305c163/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f37666339313763393763353237333335303239353061313162396339393637332e706e67)

开始时cwnd=1，为一个报文段；开始慢开始算法阶段1->2->4->8->16，到达慢开始门限（ssthresh）；切换算法，由慢开始算法切换到拥塞避免算法“加法增大”，16->17->18->19->20->21->22->23->24；到达24，收到三个重复冗余的确认ACK，执行快重传算法；执行“乘法减小”算法，把ssthresh门限减半，切换到快恢复算法，快恢复算法将cwnd调整至出现拥塞时ssthresh减半的值12；使用拥塞避免算法12->13->14->15->16->17->18->19->20......

# RST

- 端口未打开，服务器程序core dump之后重启之前。
- 请求超时，客户端想服务器传输数据时间超过服务器设置的recv超时时间。
- 服务器socket传输到一半提前关闭。
- 服务器socket已经关闭。

# socket重启 端口被占用

因为socket结束后，linux会保留此端口一定时间，据说是1~4分钟；过后才能再次被使用。

设置SO_REUSEADDR选项可以解决此问题，关闭socket后可立即再使用端口。

# 乐观锁和悲观锁

悲观锁：假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁，行锁、表锁、读锁、写锁就是在操作前先上锁。

乐观锁：假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。

# CPU占用率过高

- top查看整体机器性能
- ps -ef定位是什么后台程序
- ps -mp定位到线程或者代码
- go tool pprof -http :8080 cpu.profile

# DNS

![img](https://camo.githubusercontent.com/def82023f45116a1d8e68f02ec43a9d57cfaffa6531cbf801e737f066e08b249/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f63653537623265653634353835656531383365616530323334613262643966652e706e67)

# golang常用数据结构占用内存大小

bit位存储0/1，byte字节是8 bit。

- int64 8字节
- float64 8字节
- ascii string 1字节
- utf-8 string 1-4字节，看过一个中文是3的
- bool 1字节

# 进程间通信

- 共享存储。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据[1]：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用read()，write()等操作。

- 消息传递。消息队列可以是一种消息链表。有足够的权限的线程可以往队列中放置消息，有足够读权限的线程可以从队列中取走消息。每个消息都是一个记录，它由发送者赋予一个优先级。一个进程可以往某个队列中写入一些消息，然后终止，再让另外一个进程在以后某个时刻读出这些消息。msgtcl、msgrcv、msgsnd。

- 管道：匿名管道、命名管道。创建匿名管道pipe()系统调用，只能具有血缘关系的进程之间通信。创建命名管道mkfifo()，创建一个p类型的文件。

- 信号：传递消息，一个进程可以向另外一个进程或者另外一组进程发送信号消息，通知目标进程执行特定的代码，SEGV，KILL。

- 信号量：进程间通信处理同步互斥的机制。

# 死锁

两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。称此时系统处于死锁状态或系统产生了死锁。

银行家算法

当一个进程申请使用资源的时候，银行家算法通过先**试探**分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

![这里写图片描述](https://img-blog.csdn.net/20180508204335770?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDE0Mjcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

假设资源P1申请资源，银行家算法先试探的分配给它（当然先要看看当前资源池中的资源数量够不够），若申请的资源数量小于等于Available，然后接着判断分配给P1后剩余的资源，能不能使进程队列的某个进程执行完毕，若没有进程可执行完毕，则系统处于不安全状态（即此时没有一个进程能够完成并释放资源，随时间推移，系统终将处于死锁状态）。
若有进程可执行完毕，则假设回收已分配给它的资源（剩余资源数量增加），把这个进程标记为可完成，并继续判断队列中的其它进程，若所有进程都可执行完毕，则系统处于安全状态，并根据可完成进程的分配顺序生成安全序列（如{P0，P3，P2，P1}表示将申请后的剩余资源Work先分配给P0–>回收（Work+已分配给P0的A0=Work）–>分配给P3–>回收（Work+A3=Work）–>分配给P2–>······满足所有进程）。

# 数组与链表

数组存储在一块连续的内存，查找O(1)，插入和删除O(n)，要前移或者后移。

链表存储在分散的内存，查找O(n)，插入和删除O(1)，改变指针即可。

# 二叉树与二叉搜索树

二叉树是一种特殊的树。二叉树的每个节点最多只能有2个子节点。

![img](https://images0.cnblogs.com/blog/413416/201303/17000135-75060e3ee81847c6892d2167710b4317.png)

每个节点都不比它左子树的任意元素小，而且不比它的右子树的任意元素大。

![img](https://images0.cnblogs.com/blog/413416/201303/17001935-1b9faa8518a14f95b3bb9eb3083f683c.png)

1. 如果x等于根节点，那么找到x，停止搜索 (终止条件)

2. 如果x小于根节点，那么搜索左子树

3. 如果x大于根节点，那么搜索右子树

# 网络通信，客户端意外断开

close socket或者shutdown，recv或send调用就会马上返回，并且报错。

意外断开，正在执行recv或者send操作的一方没接受到中断通知继续等待。

keepalive机制默认7200秒没有数据传输，会向客户端发送ACK和当前 TCP序列号减一。client存在，就刷新keepalive时间，client已经断开，重复发送ACK和当前 TCP序列号减一 几次。客户端已经重启，响应是一个RST。

一般Web服务器都会提供keepalive_timeout参数，用来指定HTTP长连接的超时时间。如果设置了HTTP长连接的超时时间是60秒，Web服务软件就会启动一个定时器，如果客户端在完后一个HTTP请求后，在60秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。

# explain

- select_type：区分普通查询、联合查询、子查询等

- type：判断此次查询是 全表扫描 还是 索引扫描等
  - system：表中一条数据
  - const：主键或唯一索引查询，只返回一行数据
  - eq_ref：多表的 join 查询，表示对于前表的每一个结果，都只能匹配到后表的一行结果
  - ref：多表的 join 查询，针对于非唯一或非主键索引，或者是使用了 最左前缀 规则索引的查询
  - range：索引范围查询，通过索引字段范围获取表中部分数据记录
  - index：仅扫描所有的索引，而不扫描数据
  - all：全表扫描
- possible_keys：可能使用到的索引
- key：真正使用的索引
- key_len：索引的字节数
- res：索引的那一列被使用了
- rows：SQL要查询到的结果集需要扫描读取的数据行数
- extra：额外字段
  - using filesort：需要额外的排序操作
  - using index：覆盖索引扫描
  - using temporary：查询有使用临时表
  - using where：使用了where过滤

# URL解析详情

- DNS解析：将域名解析成 IP 地址
- TCP连接：TCP三次握手
- 发送HTTP请求
- 服务器处理请求并返回HTTP报文
- 浏览器解析渲染页面
- 断开连接：TCP四次挥手

# 三次握手

![img](https://camo.githubusercontent.com/ec0a50cbcd50b292f09039aee8545da87225f7d09154d7346acefd9003b83302/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f61313531303032383162393238613731313864643461303733323064333866642e706e67)

两次握手不行的原因是：

- 为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤
- 如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认
- 防止已失效的连接请求又传送到服务器端，因而产生错误

# 四次挥手

![image-20201229221859468](https://camo.githubusercontent.com/3257ca964a94f8cd080e8a9571478ac19c4a55a1ad60c1627593c17c2a474c20/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f696d675f636f6e766572742f62346631363061633034623563306430323230636364653262316133663934622e706e67)

确保数据能够完成传输。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET，也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

如果客户端在 ROUND 4 中发送的确认报文段在路上丢失，没有到达服务器端，服务器端在一定时间内没有收到确认就会重传 ROUND3 中的连接释放报文段。如果客户端刚发送完 ROUND4 中的确认报文段就直接关闭连接，那么服务器端就会一直不停地重传 ROUND3 中的连接释放报文段，这样会大大浪费服务器端的资源。如果客户端在 ROUND 4 中发送的确认报文段在路上丢失，没有到达服务器端，那么客户端在 2MSL 时间内还会收到来自服务器重传的连接释放报文段，然后客户端会重传确认报文段，直至服务器端接收成功为止。

# 访问IP没有加端口

传输层需要端口到端口之间的连接，http默认端口是80，https是443

# 哪些列创建索引

1. 为经常出现在关键字order by、group by、distinct后面的字段，建立索引 在这些字段上建立索引，可以有效地避免排序操作。如果建立的是复合索引，索引的字段顺序要和这些关键字后面的字段顺序一致，否则索引不会被使用
2. 在union等集合操作的结果集字段上，建立索引。
3. 为经常用作查询选择的字段，建立索引
4. 在经常用作表连接的属性上，建立索引
5. 考虑使用索引覆盖。对数据很少被更新的表，如果用户经常只查询其中的几个字段，可以考虑在这几个字段上建立索引，从而将表的扫描改变为索引的扫描
6. 定义主键的数据列一定要建立索引
7. 定义有外键的数据列一定要建立索引
8. 对于需要在指定范围内的快速或频繁查询的数据列
9. 经常用在WHERE子句中的数据列
10. 对于那些查询中很少涉及的列，重复值比较多的列不要建立索引
11. 对于定义为text、image和bit的数据类型的列不要建立索引
12. 对于经常存取的列避免建立索引
13. 限制表上的索引数目。对一个存在大量更新操作的表，所建索引的数目一般不要超过3个，最多不要超过5个。索引虽说提高了访问速度，但太多索引会影响数据的更新操作
14. 对复合索引，按照字段在查询条件中出现的频度建立索引。在复合索引中，记录首先按照第一个字段排序。对于在第一个字段上取值相同的记录，系统再按照第二个字段的取值排序，以此类推。因此只有复合索引的第一个字段出现在查询条件中，该索引才可能被使用，因此将应用频度高的字段，放置在复合索引的前面，会使系统最大可能地使用此索引，发挥索引的作用
15. 避免在取值朝一个方向增长的字段（例如：日期类型的字段）上，建立索引；对复合索引，避免将这种类型的字段放置在最前面。 由于字段的取值总是朝一个方向增长，新记录总是存放在索引的最后一个叶页中，从而不断地引起该叶页的访问竞争、新叶页的分配、中间分支页的拆分。此外，如果所建索引是聚集索引，表中数据按照索引的排列顺序存放，所有的插入操作都集中在最后一个数据页上进行，从而引起插入“热点”。
16. 删除不再使用，或者很少被使用的索引

# 聚簇索引

将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据

聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一且非空的索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键RowId来作为聚簇索引。

优势：

1. 由于行数据和聚簇索引的叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中（缓存器），再次访问时，会在内存中完成访问，不必访问磁盘。这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。

2. 辅助索引的叶子节点，存储主键值，而不是数据的存放地址。好处是当行数据放生变化时，索引树的节点也需要分裂变化；或者是我们需要查找的数据，在上一次IO读写的缓存中没有，需要发生一次新的IO操作时，可以避免对辅助索引的维护工作，只需要维护聚簇索引树就好了。另一个好处是，因为辅助索引存放的是主键值，减少了辅助索引占用的存储空间大小。

   注：我们知道一次io读写，可以获取到16K大小的资源，我们称之为读取到的数据区域为Page。而我们的B树，B+树的索引结构，叶子节点上存放好多个关键字（索引值）和对应的数据，都会在一次IO操作中被读取到缓存中，所以在访问同一个页中的不同记录时，会在内存里操作，而不用再次进行IO操作了。除非发生了页的分裂，即要查询的行数据不在上次IO操作的缓存里，才会触发新的IO操作。

3. 因为MyISAM的主索引并非聚簇索引，那么他的数据的物理地址必然是凌乱的，拿到这些物理地址，按照合适的算法进行I/O读取，于是开始不停的寻道不停的旋转。聚簇索引则只需一次I/O。（强烈的对比）

4. 不过，如果涉及到大数据量的排序、全表扫描、count之类的操作的话，还是MyISAM占优势些，因为索引所占空间小，这些操作是需要在内存中完成的。

缺点：

1. 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于 InnoDB 表，我们一般都会定义一个自增的 ID 列为主键
2. 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于 InnoDB 表，我们一般定义主键为不可更新。
3. 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

# ACID各属性的体现

- 原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log
- 持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log
- 隔离性：保证事务执行尽可能不受其他事务影响；主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）
- 一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障

# Redis持久化

- RDB将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。
- AOF将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。

# Redis模型

- 纯内存操作
- IO多路复用，可以在单线程中监听多个socket的请求，其中一个socket可读/可写时，redis去读取客户端请求，在内存中操作对应的数据，再写回到socket中。
- 非CPU密集型任务
- 单线程没有上下文切换的性能损耗，没有访问共享资源加锁的性能损耗

# go sync.map

![在这里插入图片描述](https://camo.githubusercontent.com/1049aec47338b0c71a7bdc89ae9b0baed0407fcc3deef42d67f2b8f2b3be1684/68747470733a2f2f7365676d656e746661756c742e636f6d2f696d672f72656d6f74652f313436303030303031383338353931393f773d39363726683d393537)

go map经过将生成的哈希值一分为二，前半部分是高位哈希值，后半部分是低哈希值。

高位哈希值用于确定当前的bucket有没有所存储的数据。

低位哈希值用于确定当前的数据存在哪个bucket。

hmap存储了一个指向底层bucket数组的指针。

我们存入的key和value是存储在bucket里面中，如果key和value大于128字节，那么bucket里面存储的是指向我们key和value的指针，如果不是则存储的是值。

每个bucket 存储8个key和value，如果超过就重新创建一个bucket挂在在元bucket上，持续挂接形成链表。

map的delete并非真的delete，所以对迭代器是没有影响的，是安全的。删除的核心就在那个empty。它修改了当前key的标记，而不是直接删除了内存里面的数据。真正释放内存，可以将map置为nil，等待垃圾回收器回收。

# HTTPS加密过程

![img](https://camo.githubusercontent.com/706d4adc07a1016d2f72949cf8b20b59a60191135dc8549d355175f0a9cc2d60/68747470733a2f2f696d672d626c6f672e6373646e2e6e65742f32303138303632323137343630373434323f77617465726d61726b2f322f746578742f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c3355774d5445334e7a6b334d6a513d2f666f6e742f3561364c354c32542f666f6e7473697a652f3430302f66696c6c2f49304a42516b46434d413d3d2f646973736f6c76652f3730)

# fork

子进程复制父进程的变量、内存与缓冲区，但是它们的数据空间是相互独立的，即父子进程之间不共享这些数据空间。

父子进程对打开文件是共享的。`fork()`调用后，子进程会继承父进程所打开的文件表，该文件表是由内核维护的，父子进程共享文件状态、偏移量等。也就是说，当父进程关闭文件时，子进程的文件描述符仍然有效，相应的文件表也不会被释放。

为了提高效率，`fork()`调用并不用立即复制所有的数据空间。这里采用了Copy-On-Write策略，即当父子进程任何一个需要修改数据段、堆、栈的时候，才把相应的数据复制（仅复制修改的区域）。

父子进程唯一共享的存储空间只有代码段（只读），且是`fork()`后的代码段。子进程和父进程继续执行`fork()`调用之后的命令。

# 进程的虚拟地址空间划分

![img](https://camo.githubusercontent.com/d1b0494f773b7970bede6dd9c825203020b2411aeb4d81b03464a8433a255c42/68747470733a2f2f696d672d626c6f672e6373646e2e6e65742f32303137313032373133333933333134383f77617465726d61726b2f322f746578742f6148523063446f764c324a736232637559334e6b626935755a5851766432567065476c75587a4d324d5451314e5467342f666f6e742f3561364c354c32542f666f6e7473697a652f3430302f66696c6c2f49304a42516b46434d413d3d2f646973736f6c76652f37302f677261766974792f43656e746572)

# 字典树

![字典树](https://fhfirehuo.github.io/Attacking-Java-Rookie/image/c2/trie-3.jpg)

Trie的字符串搜索时间复杂度为 O(m)，m为最长的字符串的长度，其查询性能与集合中的字符串的数量无关。其在搜索字符串时表现出的高效，使得特别适用于构建文本搜索和词频统计等应用。插入O(m)。

# 自动补全实现

redis使用zset中zrange，元素字典序排序

前缀树补全

# 单词纠错

编辑距离

# TCP与UDP

![同处于传输层的TCP协议和UDP协议，它们之间有啥区别？](https://camo.githubusercontent.com/dffc83f830a1ff589f7eb6c6f3ff8434e8ba5aae69743d485d09a44bb16ee19d/687474703a2f2f63616368652e796973752e636f6d2f75706c6f61642f61646d696e2f637573746f6d65725f636173655f696d672f323031392d31322d30352f313537353534333139342e6a7067)

![img](https://camo.githubusercontent.com/f7adf3606674cbb53970582efc3dc88d7c1dfac764d7a7e1caaeec7dd1960f97/687474703a2f2f63616368652e796973752e636f6d2f75706c6f61642f61646d696e2f637573746f6d65725f636173655f696d672f323031392d31322d30352f313537353534333235372e6a7067)

1. TCP面向连接（如打电话要先拨号建立连接）；UDP是无连接的，即发送数据之前不需要建立连接。
2. TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP尽最大努力交付，即不保证可靠交付。TCP通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。
3. UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。
4. 每一条TCP连接只能是点到点的，不可广播；UDP支持一对一、一对多、多对一和多对多的交互通信。
5. TCP对系统资源要求较多，UDP对系统资源要求较少。
6. TCP适用于大文件传输，UDP适用于小文件传输。
7. TCP报协议头20个字节，UDP为8字节。

传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。实现确认机制、重传机制、窗口确认机制。如果你不利用linux协议栈以及上层socket机制，自己通过抓包和发包的方式去实现可靠性传输，那么必须实现如下功能：发送：包的分片、包确认、包的重发；接收：包的调序、包的序号确认。

# 数据库隔离级别

读未提交、读已提交、可重复读和串行化

![彻底搞懂 MySQL 事务的隔离级别](https://camo.githubusercontent.com/ec5805930c1eb1859fa51e0f186b5f258241caf591207cca6c4ad7dd095042c2/68747470733a2f2f63646e2e6c6561726e6b752e636f6d2f75706c6f6164732f696d616765732f3230323030322f30352f33323439352f694c366a665a7869484a2e706e67216c61726765)

在读未提交隔离级别下，事务A可以读取到事务B修改过但未提交的数据。可能发生脏读、不可重复读和幻读问题，一般很少使用此隔离级别。

![彻底搞懂 MySQL 事务的隔离级别](https://camo.githubusercontent.com/5081b5c3544fc9f4c754e1bdcec8732f9498d94bedec01b227561b6c857da703/68747470733a2f2f63646e2e6c6561726e6b752e636f6d2f75706c6f6164732f696d616765732f3230323030322f30352f33323439352f42734d637579736149422e706e67216c61726765)

在读已提交隔离级别下，事务B只能在事务A修改过并且已提交后才能读取到事务B修改的数据。读已提交隔离级别解决了脏读的问题，但可能发生不可重复读和幻读问题，一般很少使用此隔离级别。

![彻底搞懂 MySQL 事务的隔离级别](https://camo.githubusercontent.com/8c14ae37f57d92f626f1203c43c54f3132f773e6c0df8fb2ca888e157079d037/68747470733a2f2f63646e2e6c6561726e6b752e636f6d2f75706c6f6164732f696d616765732f3230323030322f30352f33323439352f796a5274564f704d425a2e706e67216c61726765)

在可重复读隔离级别下，事务B只能在事务A修改过数据并提交后，自己也提交事务后，才能读取到事务B修改的数据。

![彻底搞懂 MySQL 事务的隔离级别](https://camo.githubusercontent.com/ddb4258bf9af7c807b76fb47d4d84b6e8622b87a1a22977a9722fe3280830bf4/68747470733a2f2f63646e2e6c6561726e6b752e636f6d2f75706c6f6164732f696d616765732f3230323030322f30352f33323439352f533059316e6b387976362e706e67216c61726765)

通过加锁实现（读锁和写锁）

# TCP粘包

一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。

1. 消息定长。发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
2. 设置消息边界。服务端从网络流中按消息边界分离出消息内容。在包尾增加回车换行符进行分割，例如FTP协议。
3. 将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段。

# 查找打开特定端口的进程

```
lsof -i:8080
netstat -tunpl | grep 8080
```

# 存IP地址使用什么数据类型比较好

使用32位的无符号整数（UNSIGNED INT）

无符号整数只需要4个字节，变长字符串需要额外一个字节来保存字符串的长度。

可以使用范围查询。

# CAP

一致性，可用性，分区容错性

CP：Redis、Big Table。raft投票选举中集群不对外提供服务

CA：Oracle、MySQL

MySQL异步复制，master执行完毕立即返回成功信息给客户端，而不管slave是否已经开始复制，是AP。

MySQL半同步复制，还要等待一个slave写完relay log并返回确认信息给master，master才认为此次DDL/DML语句是成功的，然后才会发送成功信息给客户端，半同步复制只需等待一个slave的回应，且等待的超时时间可以设置，超时后会自动降级为异步复制，是AP。

MySQL同步复制，master执行完毕后还需要等待所有的slave都写完了relay log才认为此次DDL/DML成功，然后才会返回成功信息给客户端，是CP。

# MVCC

在执行增删改时，才生成事务id。执行增删改是将日志记录到undo log中

在开启select时，会在第一次执行select时，生成一个read-view，是当前所有 未提交事务id + 已提交事务id的最大值组成。

mysql mvcc 底层通过 比对 read-view 中的事务id 来判断 undo log中的 数据对当前事务是否可见。

**min_trx_ids:** 我们把 readview 生成时所有未提交的 事务id 叫做 min_trx_ids(是一个数组),

**max_trx_ids:** readview 生成时系统中最大的事务id 叫做max_trx_ids

**creator_trx_id**: 把当前事务的id 叫做creator_trx_id

1. 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
2. 如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
3. 如果被访问版本的trx_id属性值大于ReadView中的max_trx_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
4. 如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

# ping用到了哪些协议

DNS协议将ping的域名转为IP，DNS用到了UDP，ARP解析MAC地址，发送一份ICMP给目标主机等待应答

# IO多路复用

|                              | select                                                       | poll                                                         | epoll                                                        |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 一个进程所能打开的最大连接数 | 单个进程所能打开的最大连接数有FD_SETSIZE宏定义（在32位的机器上，大小为1024；在64位机器上，大小为2048） | poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 | 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 |
| FD剧增后带来的IO效率问题     | 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题” | poll本质上和select没有区别                                   | 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题 |
| 消息传递方式                 | 内核需要将消息传递到用户空间，都需要内核拷贝动作             | poll本质上和select没有区别                                   | epoll通过内核和用户空间共享一块内存来实现的                  |

# pdqsort

# 长肥管道

一个连接的时延带宽积可表示为：capacity(b)=bandwidth(b/s)×round-triptime(s)。也可称它为两端的管道大小。

具有大的带宽时延乘积的网络被称为长肥网络（LongFatNetwork，即LFN），而一个运行在LFN上的TCP连接被称为长肥管道。使用长肥管道会遇到多种问题

- TCP首部中窗口大小为16bit，因此窗口大小最大为65535字节，这就将发送方发送但未被确认的数据的总长度限制到了65536字节。对于LFN管道，这可能会出现所有的数据都还未到达接收方，但是发送方已受限于窗口大小而不能继续发送的情形，这就极大的降低了网络的吞吐量。扩大窗口选项可以解决这个问题。
- 根据TCP的拥塞控制，丢失分组会导致连接进行拥塞控制，即便是由于冗余ACK而进入了快速恢复，也会使得拥塞窗口降低一半，而如果是由于超时进入了慢启动，则拥塞窗口会变为1，无论是哪一种情形，发送方允许被发送的数据量都大量减小了，这会导致网络吞吐量降低。选择确认（SACK）可以用来部分避免该问题，采用该技术使得接收方可以有选择的对无序到达的报文段进行确认而不是采用累积确认，这样被确认的报文段就不会超时，也不会有冗余的ACK。
- TCP并不对每个报文段进行RTT测量。在一个长肥网络LFN上需要更好的RTT测量机制。
- TCP对每个字节数据使用一个32bit无符号的序号来进行标识。TCP定义了最大的报文段生存时间（MSL）来限制报文段在网络中的生存时间。但是在LFN网络上，由于序号空间是有限的，在已经传输了4294967296个字节以后序号会被重用。如果网络快到在不到一个MSL的时候序号就发生了回绕，网络中就会有两个具有相同序号的不同的报文段，接收方将无法区分它们的顺序。在一个千兆比特网络（1000Mb/s）中只需要34秒就可以完成4294967296个字节的发送。使用TCP的时间戳选项的PAWS算法（保护回绕的序号）可以解决该问题。

解决：QUIC协议

# mysql的limit分页，越往后为什么越慢，怎么解决

![在这里插入图片描述](https://img-blog.csdnimg.cn/4f88b9524e8249c6a73978364e723a23.png)

利用表的覆盖索引来加速分页查询

我们都知道，利用了索引查询的语句中如果只包含了那个索引列（覆盖索引），那么这种情况会查询很快。

因为利用索引查找有优化算法，且数据就在查询索引上面，不用再去找相关的数据地址了，这样节省了很多时间。

另外Mysql中也有相关的索引缓存，在并发高的时候利用缓存就效果更好了。

在我们的例子中，我们知道id字段是主键，自然就包含了默认的主键索引。

这次我们之间查询（利用覆盖索引，只包含id列），如下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/46f3bdbde6a545acb4b942646419bede.png)
查询时间为0.2秒，相对于查询了所有列的37.44秒，提升100多倍的速度。

那么如果我们也要查询所有列，有两种方法，

方法1：子查询，id>=的形式：
![在这里插入图片描述](https://img-blog.csdnimg.cn/ab9bb47971d4472abcf57e42ae42cab2.png)
查询时间为0.2秒，简直是一个质的飞跃啊。

方法2：利用join
![在这里插入图片描述](https://img-blog.csdnimg.cn/0d5ba895b5394762aa8f0546a5abb2bf.png)

效果也差不多查询时间也很短。

# 主键使用自增和随机字符串

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。

如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

